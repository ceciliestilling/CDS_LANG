{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "e68f705d-2341-456b-8359-de78248ac417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T20:44:31.961264Z",
     "iopub.status.busy": "2022-03-01T20:44:31.960398Z",
     "iopub.status.idle": "2022-03-01T20:44:31.973373Z",
     "shell.execute_reply": "2022-03-01T20:44:31.972289Z",
     "shell.execute_reply.started": "2022-03-01T20:44:31.961143Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e80ea1-b2da-4895-b34d-90cecd014a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7aa06d38-ecb8-40f6-bc48-aea45dd65db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T19:36:09.930542Z",
     "iopub.status.busy": "2022-03-01T19:36:09.929618Z",
     "iopub.status.idle": "2022-03-01T19:36:09.940590Z",
     "shell.execute_reply": "2022-03-01T19:36:09.939349Z",
     "shell.execute_reply.started": "2022-03-01T19:36:09.930413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare tokenization\n",
    "def tokenization(input_str):\n",
    "    # Split on any non-alphanumeric character\n",
    "    tokenizer = re.compile(r\"\\W+\")\n",
    "\n",
    "    # Tokenize\n",
    "    token_list = tokenizer.split(input_str)\n",
    "\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "589e1820-592c-4f34-8858-dba5a09c8dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T19:36:12.156569Z",
     "iopub.status.busy": "2022-03-01T19:36:12.155667Z",
     "iopub.status.idle": "2022-03-01T19:36:12.169930Z",
     "shell.execute_reply": "2022-03-01T19:36:12.168974Z",
     "shell.execute_reply.started": "2022-03-01T19:36:12.156445Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep: Number of times search term is present with given collocates\n",
    "# st means search term\n",
    "def calc_st_w_coll(concordances):\n",
    "\n",
    "    st_w_coll = {}\n",
    "\n",
    "    for conc in concordances:\n",
    "        for collocate in conc:\n",
    "            if collocate in st_w_coll:\n",
    "                st_w_coll[collocate] += 1\n",
    "            else:\n",
    "                st_w_coll[collocate] = 1\n",
    "\n",
    "    return st_w_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "62590202-2e50-4467-97c1-ad32bf80238f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T19:36:13.898543Z",
     "iopub.status.busy": "2022-03-01T19:36:13.897625Z",
     "iopub.status.idle": "2022-03-01T19:36:13.913004Z",
     "shell.execute_reply": "2022-03-01T19:36:13.911759Z",
     "shell.execute_reply.started": "2022-03-01T19:36:13.898414Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep: Calculate collocates w/o search term and total of collocates\n",
    "def calc_coll_wo_st_total_coll(concordances, all_tokens, st_w_coll_dict):\n",
    "    coll_wo_st = {}\n",
    "    total_coll = {}\n",
    "\n",
    "    for conc in concordances:\n",
    "        for collocate in conc:\n",
    "            total_count = all_tokens.count(collocate)\n",
    "            total_coll[collocate] = total_count\n",
    "            wo_st = total_count - st_w_coll_dict[collocate]\n",
    "            coll_wo_st[collocate] = wo_st\n",
    "\n",
    "    return (coll_wo_st, total_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "1475cd52-84a4-4e71-9c6f-8e662e1c03fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T19:36:15.336816Z",
     "iopub.status.busy": "2022-03-01T19:36:15.335879Z",
     "iopub.status.idle": "2022-03-01T19:36:15.349712Z",
     "shell.execute_reply": "2022-03-01T19:36:15.348706Z",
     "shell.execute_reply.started": "2022-03-01T19:36:15.336680Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep: Number of times search term is present without any given collocate\n",
    "def calc_stcount_st_wo_coll(all_tokens, st, st_w_coll_dict):\n",
    "    st_wo_coll = {}\n",
    "\n",
    "    # Number of times the search term occurs across the corpus\n",
    "    st_count = all_tokens.count(st)\n",
    "    for collocate, count in st_w_coll_dict.items():\n",
    "        st_wo_coll[collocate] = st_count - count\n",
    "\n",
    "    return (st_count, st_wo_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "60e7fd83-89c0-4a46-bdcd-7a97e4597d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T19:38:58.405239Z",
     "iopub.status.busy": "2022-03-01T19:38:58.404169Z",
     "iopub.status.idle": "2022-03-01T19:38:58.418513Z",
     "shell.execute_reply": "2022-03-01T19:38:58.417524Z",
     "shell.execute_reply.started": "2022-03-01T19:38:58.405102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep: The expected frequency of a given collocate occurring with the search term\n",
    "def calc_exp_freq(total_coll, stcount, corpus_size):\n",
    "\n",
    "    exp_freq = {}\n",
    "\n",
    "    for collocate in total_coll:\n",
    "        exp_freq[collocate] = (stcount * total_coll[collocate]) / corpus_size\n",
    "\n",
    "    return exp_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "f1dfee48-2b85-4a79-856a-476e1ddb65fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T19:38:59.814987Z",
     "iopub.status.busy": "2022-03-01T19:38:59.813905Z",
     "iopub.status.idle": "2022-03-01T19:38:59.831136Z",
     "shell.execute_reply": "2022-03-01T19:38:59.830248Z",
     "shell.execute_reply.started": "2022-03-01T19:38:59.814850Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep: The mutual information for any given collocate to the search term\n",
    "def calc_mut_inf(st_w_coll, exp_freq):\n",
    "\n",
    "    mut_inf = {}\n",
    "\n",
    "    for collocate in st_w_coll:\n",
    "        mut_inf[collocate] = math.log(st_w_coll[collocate] / exp_freq[collocate])\n",
    "\n",
    "    return mut_inf\n",
    "\n",
    "\n",
    "# Write headers to csv - separately from appending, since this also overwrites the old file\n",
    "def write_csv(outfile, st_w_coll, mut_inf):\n",
    "\n",
    "    with open(outfile, \"w\", encoding=\"utf-8\") as fh:\n",
    "        fh.write(\"collocate,raw_frequency,MI\\n\")\n",
    "\n",
    "    with open(outfile, \"a\", encoding=\"utf-8\") as fh:\n",
    "        for collocate in st_w_coll:\n",
    "            fh.write(f\"{collocate},{st_w_coll[collocate]},{mut_inf[collocate]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "530f72e6-4014-4800-9157-9d34273a8b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T22:12:05.583862Z",
     "iopub.status.busy": "2022-03-01T22:12:05.582967Z",
     "iopub.status.idle": "2022-03-01T22:12:05.607003Z",
     "shell.execute_reply": "2022-03-01T22:12:05.606202Z",
     "shell.execute_reply.started": "2022-03-01T22:12:05.583737Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(data_dir, st, window_size, sample_num):\n",
    "    # Output file is named after the st and window size\n",
    "    #outpath = \"output\"\n",
    "    outfile = os.path.join(f\"{st}_{window_size}.csv\")\n",
    "\n",
    "    # Make everything lowercase\n",
    "    st = st.lower()\n",
    "\n",
    "    # The list of all tokens in the corpus\n",
    "    tokens = []\n",
    "\n",
    "    # data_dir is already converted to a Path in ArgumentParser\n",
    "    for i, file_path in enumerate(\n",
    "        data_dir.glob(\"*.txt\")\n",
    "    ):  # enumerate() adds a counter to an iterable and returns it in a form of enumerating object\n",
    "        # Only use a subset of files if running as demo\n",
    "        if i == sample_num:\n",
    "            break\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "            # Splits the whole novel-content string into tokens on non-word characters\n",
    "            tokens += tokenization(content)\n",
    "\n",
    "    # Lowercase tokens yes please\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Total number of tokens in corpus\n",
    "    corpus_size = len(tokens)\n",
    "\n",
    "    # Locations of search term in the token list\n",
    "    st_indices = [i for i, token in enumerate(tokens) if token == st.lower()]\n",
    "\n",
    "    # A list of tokens slices +- window_size around search term\n",
    "    concordances = [\n",
    "        tokens[max(0, i - window_size) : i + window_size + 1] for i in st_indices\n",
    "    ]\n",
    "\n",
    "    # Filters out the exact search term that we are checking against, but not other occurences of the search term\n",
    "    for conc in concordances:\n",
    "        # Removes the window_size'th element (exact middle) of concordance line, which is the search term\n",
    "        conc.pop(window_size)\n",
    "\n",
    "    # Number of times search term is present with given collocates\n",
    "    st_w_coll = calc_st_w_coll(concordances)\n",
    "\n",
    "    # coll_wo_st: Number of times given collocate occurs without search term\n",
    "    # total_coll: Total number of times a given collocate occurs\n",
    "    coll_wo_st, total_coll = calc_coll_wo_st_total_coll(concordances, tokens, st_w_coll)\n",
    "\n",
    "    # R1 / stcount: Number of times the search term occurs across the corpus\n",
    "    # st_wo_coll: Number of times search term is present without any given collocate\n",
    "    stcount, st_wo_coll = calc_stcount_st_wo_coll(tokens, st, st_w_coll)\n",
    "\n",
    "    # The expected frequency of a given collocate occurring with the search term\n",
    "    exp_freq = calc_exp_freq(total_coll, stcount, corpus_size)\n",
    "\n",
    "    # The MI for any given collocate to the search term\n",
    "    mut_inf = calc_mut_inf(st_w_coll, exp_freq)\n",
    "\n",
    "    # Write 3 columns: collocate, raw_frequency, MI\n",
    "    write_csv(outfile, st_w_coll, mut_inf)\n",
    "\n",
    "    print(\"Data written to: \" + outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "6deeb24c-7e42-409b-b05f-77083d44afcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-01T22:16:35.770356Z",
     "iopub.status.busy": "2022-03-01T22:16:35.769413Z",
     "iopub.status.idle": "2022-03-01T22:16:35.800244Z",
     "shell.execute_reply": "2022-03-01T22:16:35.799197Z",
     "shell.execute_reply.started": "2022-03-01T22:16:35.770213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to: s_5.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "del sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"calculate collocates for a specific search term\"\n",
    "    )\n",
    "    parser.add_argument(\"st\", help=\"the search term\")\n",
    "    parser.add_argument(\n",
    "        \"-w\",\n",
    "        \"--window_size\",\n",
    "        type=int,\n",
    "        default=5,\n",
    "        help=\"the number of words on both sides of the search term to look for collocates in\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-s\",\n",
    "        \"--sample_num\",\n",
    "        type=int,\n",
    "        help=\"whether to only use a subset of files and how many to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--data_dir\",\n",
    "        type=Path,\n",
    "        default=Path(\"./data/\"),\n",
    "        help=\"the directory containing all of your text files to analyze\",\n",
    "    )\n",
    "    # Execute parse_args()\n",
    "    args, unknown = parser.parse_known_args(\"st\")\n",
    "\n",
    "    main(\n",
    "        data_dir=args.data_dir,\n",
    "        st=args.st,\n",
    "        window_size=args.window_size,\n",
    "        sample_num=args.sample_num,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
